<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, maximum-scale=1">

	<title>LFO! - Face Recognition</title>
	<link rel="icon" href="favicon.png" type="image/png">
	<link rel="shortcut icon" href="favicon.ico" type="img/x-icon">

	<link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
	<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,300,800italic,700italic,600italic,400italic,300italic,800,700,600' rel='stylesheet' type='text/css'>

	<link href="css/bootstrap.css" rel="stylesheet" type="text/css">
	<link href="css/style.css" rel="stylesheet" type="text/css">
	<link href="css/font-awesome.css" rel="stylesheet" type="text/css">
	<link href="css/responsive.css" rel="stylesheet" type="text/css">
	<link href="css/magnific-popup.css" rel="stylesheet" type="text/css">
	<link href="css/animate.css" rel="stylesheet" type="text/css">

	<script type="text/javascript" src="js/jquery.1.8.3.min.js"></script>
	<script type="text/javascript" src="js/bootstrap.js"></script>
	<script type="text/javascript" src="js/jquery-scrolltofixed.js"></script>
	<script type="text/javascript" src="js/jquery.easing.1.3.js"></script>
	<script type="text/javascript" src="js/jquery.isotope.js"></script>
	<script type="text/javascript" src="js/wow.js"></script>
	<script type="text/javascript" src="js/classie.js"></script>
	<script type="text/javascript" src="js/magnific-popup.js"></script>
	<script src="contactform/contactform.js"></script>

	<!-- =======================================================
    Theme Name: Knight
    Theme URL: https://bootstrapmade.com/knight-free-bootstrap-theme/
    Author: BootstrapMade
    Author URL: https://bootstrapmade.com
	======================================================= -->

</head>

<body>
	<nav class="main-nav-outer" id="test">
		<!--main-nav-start-->
		<div class="container">
			<ul class="main-nav">
				<li><a href="index.html#computer">Back to Home</a></li>
				<li><a href="#pixel">Pixel</a></li>
				<li><a href="#detection">Face Detection</a></li>
				<li><a href="#extraction">Feature Extraction</a></li>
				<li><a href="#recognition">Classification / Recognition</a></li>
			</ul>
			<a class="res-nav_click" href="#"><i class="fa fa-bars"></i></a>
		</div>
	</nav>
	<!--main-nav-end-->

	<section class="main-section client-part" id="client">
		<!--main-section client-part-start-->
		<div class="container">
			<b class="quote-right wow fadeInDown delay-03"><i class="fa fa-desktop"></i></b>
			<div class="row">
				<div class="col-lg-12">
					<p class="client-part-haead wow fadeInDown delay-05">Computer Face Recognition</p>
				</div>
			</div>
		</div>
	</section>
	<!--main-section client-part-end-->

	<section class="main-section alabaster" id="pixel">
		<!--main-section alabaster-start-->
		<div class="container">
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work" style="text-align: center;">
					<h2 style="text-align: center;">Pixel</h2>
					<P>The <b>Bottom-up Stimulus</b> for Computers in Face Recognition</P>
					<figure class="col-lg-12 col-sm-12 fadeInDown">
						<img src="img/pixel.png" alt="">
					</figure>
				</div>
			</div>
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<p class="padding-b-small"> </p>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<h3>Digital images are comprised of tiny amounts of information.</h3>
							<p>The pixel is the unit of measure for a digital image.</p> 
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-02s">
							<h3>One pixel represents a single color.</h3>
							<p class="padding-b">Colors can be represented in hex, RGB, gray-scale intensity and other identification schemes.</p>
							<div class="col-sm-6">
								<figure style="text-align: center;">
									<img src="img/pixel-red.png" alt="">
								</figure>	
							</div>
							<div class="col-sm-6" style="text-align: center;">
								<h3>Example representation schemes (RGB): </h3>
								<p class="padding-b-small"> </p>
								<table class="fadeInDown">
								  <tr>
								    <th>Base</th>
								    <th>Red</th>
								    <th>Green</th>
								    <th>Blue</th>
								  </tr>
								  <tr>
								    <td>Decimal</td>
								    <td>255</td>
								    <td>0</td>
								    <td>0</td>
								  </tr>
								  <tr>
								    <td>Octal (8)</td>
								    <td>377</td>
								    <td>0</td>
								    <td>0</td>
								  </tr>
								  <tr>
								    <td>Hex (16)</td>
								    <td>FF</td>
								    <td>00</td>
								    <td>00</td>
								  </tr>
								  <tr>
								    <td>Binary</td>
								    <td>1111 1111</td>
								    <td>0000 0000</td>
								    <td>0000 0000</td>
								  </tr>
								</table>
							</div>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-03s">
							<p class="padding-b-small"> </p>
							<h3>Pixels are identified by their location within the coordinate grid.</h3>
							<p class="padding-b-small">Pixels are assembled in a grid system. Each one has coordinates. Each pixel is specified by its position within the grid system as identified by (x-axis, y-axis) using integers.</p>
							<div class="col-sm-12" style="text-align: center;">
								<figure>
									<img src="img/pixel-grid.jpg" alt="">
								</figure>	
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
	</section>
	<!--main-section alabaster-end-->

	<section class="main-section alabaster" id="detection">
		<!--main-section alabaster-start-->
		<div class="container">
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work" style="text-align: center;">
					<h2 style="text-align: center;">Face Detection</h2>
					<figure>
						<img src="img/face-det.png" alt="">
					</figure>
					<P class="padding-t-small">Face detection is a two class problem where we have to decide if there is a face or not in a picture. Here, we introduce <b>four</b> different general approaches: </P>
				</div>
			</div>
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<p class="padding-b-small"> </p>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<h3>Knowledge-based methods</h3>
							<p>These are rule-based methods. They try to capture our knowledge of faces, and translate them into a set of rules. It’s easy to guess some simple rules. For example, a face usually has two symmetric eyes, and the eye area is darker than the cheeks. Facial features could be the distance between eyes or the color intensity difference between the eye area and the lower zone. </p>
							<P>The big problem with these methods is the difficulty in building an appropriate set of rules. There could be many false positives if the rules were too general. On the other hand, there could be many false negatives if the rules were too detailed.</p> 
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<h3>Feature-invariant methods</h3>
							<p>Algorithms that try to find invariant features of a face despite it’s angle or position. The idea is to overcome the limits of our instinctive knowledge of faces.</p>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<h3>Template matching</h3>
							<p>Template matching methods try to define a face as a function. We try to find a standard template of all the faces. Different features can be defined independently. For example, a face can be divided into eyes, face contour, nose and mouth. Also a face model can be built by edges. A face can also be represented as a silhouette. Other templates use the relation between face regions in terms of brightness and darkness. These standard patterns are compared to the input images to detect faces. </p>
							<P>This approach is simple to implement, but it’s inadequate for face detection. It cannot achieve good results with variations in pose, scale and shape. </p>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<h3>Appearance-based methods</h3>
							<p>A template matching method whose pattern database is learnt from a set of training images.</p>
							<P>In general, appearance-based methods rely on techniques from statistical analysis and machine learning to find the relevant characteristics of face images. Some appearance-based methods work in a probabilistic network. An image or feature vector is a random variable with some probability of belonging to a face or not. Another approach is to to define a discriminant function between face and non-face classes. </p>
						</div>
					</div>
				</div>
			</div>
			<div class="container">
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<p class="padding-b"></p>
					<p class="padding-b"></p>
					<h2 style="text-align: center;">Example: Histogram of Oriented Gradients Method (2005)</h2>
					<P class="padding-t-small">TLDR: This is a template matching algorithm. Taking a gray-scale image, we represent the entire image by using arrows, at each pixel, to point towards the direction that the image is getting darker. And then we can see if the pattern of arrows resembles a face or not. </P>
				</div>
			</div>
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<p class="padding-b"> </p>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-8">
								<h3>Calculate Gradiant (the arrow)</h3>
								<p> Taking the gray-scale picture above, we can draw an arrow at the marked pixel showing in which direction the image is getting darker. </p>
								<P>If you repeat that process for every single pixel in the image, you end up with every pixel being replaced by an arrow. These arrows are called <b>gradients</b> and they show the flow from light to dark across the entire image:</P> 
								<p class="padding-b"></p>
							</div>
							<div class="col-sm-4">
								<img src="img/det-arrow.gif" alt="">
							</div>
						</div>
						<div class="featured-box-col2 wow fadeInRight delay-01s" style="text-align: center;">
							<img src="img/gradient-full.gif" alt="">
							<p class="padding-b">By only considering the direction that brightness changes, we reduces the influence of different illumination. </p>
						</div>
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<p class="padding-b-small">Saving the gradient for every single pixel gives us way too much detail. We end up missing the forest for the trees. It would be better if we could just see the basic flow of lightness/darkness at a higher level so we could see the basic pattern of the image</p>
						</div>
						<div class="featured-box-col2 wow fadeInRight delay-01s" style="text-align: center;">
							<img src="img/gradient-simple.gif" alt="">
							<p class="padding-b">The original image is turned into a HOG representation that captures the major features of the image regardless of image brightnesss.</p>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<h3>HOG Matching</h3>
							<p class="padding-b">To find faces in this HOG image, all we have to do is find the part of our image that looks the most similar to a known HOG pattern that was extracted from a bunch of other training faces:</p>
						</div>
						<div class="featured-box-col2 wow fadeInRight delay-01s" style="text-align: center;">
							<img src="img/gradient-match.png" alt="">
						</div>
					</div>
				</div>
			</div>
		</div>
	</section>
	<!--main-section alabaster-end-->

	<section class="main-section alabaster" id="extraction">
		<!--main-section alabaster-start-->
		<div class="container">
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<h2 style="text-align: center;">Feature Extraction</h2>			
					<P class="padding-t-small">This feature extraction process can be defined as the procedure of extracting relevant information from a face image. This information must be valuable to the later step of identifying the subject with an acceptable error rate. The feature extraction process must be efficient in terms of computing time and memory usage. The output should also be optimized for the classification step. </P>
				</div>
			</div>
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<p class="padding-b-small"> </p>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<h3>Dimension Reduction</h3>
							<p>The performance of a classifier depends on the amount of sample images, number of features and classifier complexity.</p>
							<p> Rationale for reducing dimensionality:
								<ul>
									<li>
										"Curse of dimensionality" or "Peaking phenomenon": added features may degrade the performance of a classification algorithm.
									</li>
									<li>
										Speed & Memory. The classifier will be faster and will use less memory if feature number is small.
									</li>
									<li>
										a large set of features can result in a false positive when these features are redundant.
									</li>
								</ul>
								<p>Ultimately, the number of features must be carefully chosen. Too less or redundant features can lead to a loss of accuracy of the recognition system.</p>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<h3>Feature selection</h3>
							<p>Features are extracted from the face images, then a optimum subset of these features is selected. It aims to select a subset of the extracted features that cause the smallest classification error. Dimension reduction method can be embedded in the selection method. </p>
						</div>
					</div>
				</div>
			</div>
			<div class="container">
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<p class="padding-b"></p>
					<p class="padding-b"></p>
					<h2 style="text-align: center;">Example: Eigenfaces</h2>
					<P class="padding-t-small">TLDR: This feature extraction algorithm uses the numerical method of <b>principle component analysis</b> (PCA) to select a representative set of features that, when combined linearly, best describes faces in a low dimension. </P>
				</div>
			</div>
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<p class="padding-b"> </p>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-4">
								<h3>Space of Faces</h3>
								<p> If we take small images of faces as the <b>feature vector</b>, without detecting local features, then, for example, a 100x100 image is considered a 10000 dimensional feature vector. Each of these vectors are a location in a 10000 dimensional vector space. <b>Practically any vector in this space is a 100x100 image</b>.</p>
								<P>As these are vectors just like any other vector, we can compute difference vectors, average vectors, sum of vectors etc. The difference of two face-vectors is obviously not a face, it is just a difference image.</P> 
								<p class="padding-b"></p>
							</div>
							<div class="col-sm-4" style="text-align: center;">
								<p class="padding-b-small"></p>
								<img src="img/face-space.png" alt="">
							</div>
							<div class="col-sm-4" style="text-align: center;">
								<img src="img/face-vector-addition.png" alt="">								
							</div>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-12">
								<h3>Compact Representation</h3>
								<p class="padding-b">If we can find <b>a smaller set of basis vectors</b> that can be used to reconstruct the vectors in the dataset, we can represent them in a more compact way. This process of finding a smaller set of basis vectors to represent the data is called <b>dimensionality reduction</b>. For the space of faces this means: we need to find some set of vectors (corresponding to images) that can be used to mix any face image. If we can manage to find such a set, we will have a much more compact representation of faces.</p>
							</div>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-12">
								<h3>Principal Component Analysis (PCA)</h3>
								<p>The Principal Component Analysis is the tool to find this subspace, find a new set of basis vectors that can be used to mix any data vector.</p>
								<ul>
									<li>The first step is to find the average vector using all the points. For the space of faces this would be the average face.</li>
									<li>Then iterating through all the points we can build a covariance matrix A that represents the distribution of the points around the average. The A matrix maps the unit hypersphere to a “hyper-ellipse” corresponding to the distribution of data points. In the direction where the data points have significant variation the ellipse will be large, on other directions where there is none or little variation, the ellipse will be small, or flat.</li>
									<li>We can then use either the <b>eigendecomposition or the SVD</b> on matrix A –which is a symmetric matrix –to find these directions as well as the scaling factors in those direction.</li>
									<li>By analyzing all the eigenvectors we get and the corresponding eigenvalues, we can come up with a new set of basis vectors by simply keeping the eigenvectors with large eigenvalues and dropping vectors of low eigenvalues.</li>
								</ul>
							</div>
						</div>
						<div class="featured-box-col2 wow fadeInRight delay-01s" style="text-align: center;">
							<img src="img/pca.png" alt="">
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-7">
								<h3>Eigenfaces</h3>
								<p class="padding-t-small">Eigenfacesare the significant eigenvectors of the face dataset. Using the eigenfaces, which are really images, any face image can be mixed using a simple linear combination. This means we can represent any face with weights of the eigenfaces.</p>
								<p class="padding-t-small">While some eigenfacesseem to correspond to real features such as beard or glasses, in general eigenfacesare not faces. They are just difference images used to recreate any face in the dataset.</p>
							</div>
							<div class="col-sm-5">
								<div class="featured-box-col2 wow fadeInRight delay-01s" style="text-align: center;">
									<img src="img/face-avg-eigen.png" alt="">
									<p class="padding-t-small">First image is the average face, the others are the eigenfaces.</p>
								</div>
							</div>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-7">
								<h3>Feature Selection</h3>
								<p class="padding-t-small">If the eigenfacesare chosen properly, eg: we include all eigenfaces with larger eigenvalues, any face in the dataset can be reconstructed by a linear combination of the eigenfaces. To come up with these weights for a real face image, we simply need to multiply this 10000 dimensional input vector by a rotation matrix and drop all components with indices greater than K (the number of features we want to keep).</p>
							</div>
							<div class="col-sm-5">
								<div class="featured-box-col2 wow fadeInRight delay-01s" style="text-align: center;">
									<img src="img/face-lc.png" alt="">
									<p>x is an N dimensional feature vector. v1, v2,..., vk are eigenfaces.</p>
									<p>x = x_avg + a1v1 + a1v2 + ... + akvk</p>
								</div>
							</div>
						</div>
					</div>

					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-12">
								<h3>Face detection with eigenfaces</h3>
								<p>The eigenfacesneed to be computed only once, and then all faces in the database can be represented by a set of weights. This is a much more compact representation. </p>
								<p>Then, to <b>verify</b> if there is a face on a new image we simply need to compute the <b>reconstruction with eigenfaces</b> and check if the reconstruction matches the original image. If it does, we are likely dealing with a face image.</p>
								<p>To <b>identify</b> the face we need to find the closest weight-vector in the database and see if they are closed then some distance threshold.</p>
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
	</section>
	<!--main-section alabaster-end-->

	<section class="main-section alabaster" id="recognition">
		<!--main-section alabaster-start-->
		<div class="container">
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<h2 style="text-align: center;">Face Classification and Recognition</h2>
					<P class="padding-t-small"> Appearance-based face recognition algorithms use a wide variety of classification methods. Sometimes two or more classifiers are combined to achieve better results. On the other hand, most model-based algorithms match the samples with the model or template. </P>
					<p>Then, a learning method is can be used to improve the algorithm - supervised, unsupervised or semi-supervised. Unsupervised learning is the most difficult approach, as there are no tagged examples. However, many face recognition applications include a tagged set of subjects. Consequently, most face recognition systems implement supervised learning methods. There are also cases where the labeled data set is small. Sometimes, the acquisition of new tagged samples can be infeasible. Therefore, semi-supervised learning is required.</p>
					<p>One way or another, classifiers have a big impact in face recognition. Classification methods are also generally used in many areas like data mining, finance, signal decoding, voice recognition, natural language processing or medicine. 2 concepts that are key in building a classifier - similarity and probability. </p>
					<p class="padding-b"></p>
				</div>	
				<div class="col-lg-12 col-sm-12 featured-work">
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-12">
								<h3>Classifiers</h3>
								<ul>
									<li>Similarity: This approach is intuitive and simple. Patterns that are similar should belong to the same class. The idea is to establish a metric that defines similarity and a representation of the same-class samples. For example, the metric can be the euclidean distance. The representation of a class can be the mean vector of all the patterns belonging to this class.</li>
									<li>Probability: Some classifiers are build based on a probabilistic approach. Bayes decision rule is often used. The rule can be modified to take into account different factors that could lead to mis-classification. 
										<ul>
											<li>Bayesian: Assign pattern to the class with the highest estimated posterior probability. Eg: a Maximum A Posteriori (MAP) decision rule: 
												<img src="img/MAP.png" alt=""> where wi are the face classes and Z an image in a reduced PCA space.</li>
											<li>Logistic Classifier: Predicts probability using logistic curve method.</li>
											<li>Parzen Classifier: Bayesian classifier with Parzen density estimates.</li>
										</ul>
									</li>
								</ul>
							</div>
						</div>
					</div>
				</div>
			</div>

			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<p class="padding-b"></p>
					<p class="padding-b"></p>
					<h2 style="text-align: center;">Example: Neural Network</h2>
					<figure style="text-align: center;">
						<img src="img/nn.png" alt="">
					</figure>
					<P class="padding-t-small">Combining the idea of face detection and feature extraction ideas above, we see a wide variety of comprehensive face recognition algorithms applied in computer vision. We can summarize them into three different broad categories: <b>template matching, statistical approach and neural network</b>. The examples above corresponds to ideas within template matching and statistical category. Here, we want to show an example of how <b>neural network face recognition algorithm</b> works. </P>
				</div>
			</div>
			<div class="row">
				<div class="col-lg-12 col-sm-12 featured-work">
					<p class="padding-b"> </p>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-6">
								<h3>Which measurements should we collect from each face to build our known face database? Ear size? Nose length? Eye color? </h3>
								<p> The measurements that seem obvious to us humans (like eye color) don’t really make sense to a computer looking at individual pixels in an image. Researchers have discovered that the most accurate approach is to let the computer figure out the measurements to collect itself. <b>Deep learning</b> does a better job than humans at <b>figuring out which parts of a face are important to measure</b>.
								<p class="padding-b">The solution is to train a Deep Convolutional Neural Network to generate a number of different measurements for each face.</p>
								<h3>Training</h3>
								<p>The training process works by looking at 3 face images at a time:
									<ul>
										<li>Load a training face image of a known person</li>
										<li>Load another picture of the same known person</li>
										<li>Load a picture of a totally different person</li>
									</ul>
								</p>
								<p>Then the algorithm looks at the measurements it is currently generating for each of those three images. It then tweaks the neural network slightly so that it makes sure the measurements it generates for #1 and #2 are slightly closer while making sure the measurements for #2 and #3 are slightly further apart.
								</p>
								<p class="padding-b"></p>
							</div>
							<div class="col-sm-6" style="text-align: center;">
								<img src="img/nn-triplet.png" alt="">
							</div>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-6">
								<img src="img/face-encoding.png" alt="">
							</div>
							<div class="col-sm-6">
								<p class="padding-t-small">Machine learning people call these measurements of each face an <b>embedding</b>. The idea of reducing complicated raw data like a picture into a list of computer-generated numbers comes up a lot in machine learning (especially in language translation).</p>
								<p class="padding-t-small">This process of training a convolutional neural network to output face embeddings requires <b>a lot of data and computer power</b>. With days of continuous training to get good accuracy, we will have a trained network that can generate measurements for any face, even ones it has never seen before! The network should generate nearly the same numbers when looking at two different pictures of the same person.</p>
							</div>
						</div>
					</div>
					<div class="featured-box">
						<div class="featured-box-col2 wow fadeInRight delay-01s">
							<div class="col-sm-12">
								<h3>Recognition</h3>
								<p>This last step is actually the easiest step in the whole process. All we have to do is find the person in our database of known people who has the closest measurements to our test image. And you can do that by using any basic machine learning classifier (eg: nearest neighbor, or the classifiers mentioned above, etc.). </p>
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
	</section>
	<!--main-section alabaster-end-->
	<footer class="footer">
		<div class="container">
			<span class="copyright">&copy; Knight Theme. All Rights Reserved</span>
			<div class="credits">
				<!--
          All the links in the footer should remain intact.
          You can delete the links only if you purchased the pro version.
          Licensing information: https://bootstrapmade.com/license/
          Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Knight
        -->
				<a href="https://bootstrapmade.com/bootstrap-agency-templates/">Bootstrap Agency Templates</a> by <a href="https://bootstrapmade.com/">BootstrapMade</a>
			</div>
		</div>
	</footer>


	<script type="text/javascript">
		$(document).ready(function(e) {

			$('#test').scrollToFixed();
			$('.res-nav_click').click(function() {
				$('.main-nav').slideToggle();
				return false

			});

      $('.Portfolio-box').magnificPopup({
        delegate: 'a',
        type: 'image'
      });

		});
	</script>

	<script>
		wow = new WOW({
			animateClass: 'animated',
			offset: 100
		});
		wow.init();
	</script>


	<script type="text/javascript">
		$(window).load(function() {

			$('.main-nav li a, .servicelink').bind('click', function(event) {
				var $anchor = $(this);

				$('html, body').stop().animate({
					scrollTop: $($anchor.attr('href')).offset().top - 102
				}, 1500, 'easeInOutExpo');
				/*
				if you don't want to use the easing effects:
				$('html, body').stop().animate({
					scrollTop: $($anchor.attr('href')).offset().top
				}, 1000);
				*/
				if ($(window).width() < 768) {
					$('.main-nav').hide();
				}
				event.preventDefault();
			});
		})
	</script>

	<script type="text/javascript">
		$(window).load(function() {


			var $container = $('.portfolioContainer'),
				$body = $('body'),
				colW = 375,
				columns = null;


			$container.isotope({
				// disable window resizing
				resizable: true,
				masonry: {
					columnWidth: colW
				}
			});

			$(window).smartresize(function() {
				// check if columns has changed
				var currentColumns = Math.floor(($body.width() - 30) / colW);
				if (currentColumns !== columns) {
					// set new column count
					columns = currentColumns;
					// apply width to container manually, then trigger relayout
					$container.width(columns * colW)
						.isotope('reLayout');
				}

			}).smartresize(); // trigger resize to set container width
			$('.portfolioFilter a').click(function() {
				$('.portfolioFilter .current').removeClass('current');
				$(this).addClass('current');

				var selector = $(this).attr('data-filter');
				$container.isotope({

					filter: selector,
				});
				return false;
			});

		});
	</script>

</body>

</html>
